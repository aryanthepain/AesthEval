{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c90728",
   "metadata": {},
   "source": [
    "# AesthEval — Train models\n",
    "\n",
    "This notebook trains Early / Late / Hybrid fusion models\n",
    "on `all_features.csv` from previous step and saves every model + preprocessing artifact\n",
    "into a specified models directory for later comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9e77d",
   "metadata": {},
   "source": [
    "## PARAMETERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set. DATA_PATH= ./all_features.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./all_features.csv\"   # path to the dataset\n",
    "MODELS_DIR = \"./aesth_models\"      # directory to save models & artifacts\n",
    "RANDOM_STATE = 420                          # global random seed\n",
    "SAMPLE_SIZE = None                         # set to integer N to use N random samples; set to None to use full dataset\n",
    "EARLY_RF_N_ESTIMATORS = 300                # RF estimators for early-fusion baseline\n",
    "BASE_RF_N_ESTIMATORS = 200                 # RF estimators for per-stem base models\n",
    "HYBRID_GBR_N_ESTIMATORS = 400              # GBR estimators for hybrid model\n",
    "SAVE_PREPROCESSORS = True                  # whether to save preprocessing artifacts\n",
    "# ============================================\n",
    "print('Parameters set. DATA_PATH=', DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876545c",
   "metadata": {},
   "source": [
    "## Imports and create model directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fdcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models directory: aesth_models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, time, datetime, gc\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import joblib # to save the models\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82156f1",
   "metadata": {},
   "source": [
    "### create directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ae37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(MODELS_DIR)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Models directory:', MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510f176",
   "metadata": {},
   "source": [
    "## Utility functions for saving artifacts and logging experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67027d",
   "metadata": {},
   "source": [
    "### Timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib, datetime\n",
    "\n",
    "def timestamp():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29f12c",
   "metadata": {},
   "source": [
    "### to hash the object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3848dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_obj(obj):\n",
    "    s = json.dumps(obj, sort_keys=True, default=str).encode()\n",
    "    return hashlib.md5(s).hexdigest()[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321d6dd",
   "metadata": {},
   "source": [
    "### to save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19667990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifact(obj, name_prefix, models_dir=MODELS_DIR, metadata=None):\n",
    "    ts = timestamp()\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    base_name = f\"{name_prefix}_{ts}_{hash_obj(metadata)}\"\n",
    "    joblib_path = models_dir / f\"{base_name}.joblib\"\n",
    "    json_path = models_dir / f\"{base_name}.json\"\n",
    "    joblib.dump(obj, joblib_path)\n",
    "    metadata_to_save = dict(metadata)\n",
    "    metadata_to_save.update({\n",
    "        \"artifact\": str(joblib_path.name),\n",
    "        \"saved_at\": ts\n",
    "    })\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(metadata_to_save, f, indent=2, default=str)\n",
    "    print(f\"Saved: {joblib_path.name}, metadata: {json_path.name}\")\n",
    "    return str(joblib_path), str(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39310c",
   "metadata": {},
   "source": [
    "### to log it down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_CSV = MODELS_DIR / \"experiments_log.csv\"\n",
    "def log_experiment(row_dict, experiments_csv=EXPERIMENTS_CSV):\n",
    "    df_row = pd.DataFrame([row_dict])\n",
    "    if experiments_csv.exists():\n",
    "        df_row.to_csv(experiments_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(experiments_csv, index=False)\n",
    "    print(\"Logged experiment:\", row_dict.get('name'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f934865e",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading:', DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Original shape:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c20ddb",
   "metadata": {},
   "source": [
    "### Less samples to check code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc790a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./all_features.csv\n",
      "Original shape: (500, 280)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>harmonic_mfcc_mean_0</th>\n",
       "      <th>harmonic_mfcc_mean_1</th>\n",
       "      <th>harmonic_mfcc_mean_2</th>\n",
       "      <th>harmonic_mfcc_mean_3</th>\n",
       "      <th>harmonic_mfcc_mean_4</th>\n",
       "      <th>harmonic_mfcc_mean_5</th>\n",
       "      <th>harmonic_mfcc_mean_6</th>\n",
       "      <th>harmonic_mfcc_mean_7</th>\n",
       "      <th>harmonic_mfcc_mean_8</th>\n",
       "      <th>...</th>\n",
       "      <th>memorability_n_annotators</th>\n",
       "      <th>clarity</th>\n",
       "      <th>clarity_std</th>\n",
       "      <th>clarity_n_annotators</th>\n",
       "      <th>naturalness</th>\n",
       "      <th>naturalness_std</th>\n",
       "      <th>naturalness_n_annotators</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_annotators</th>\n",
       "      <th>harmonic_tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-234.011032</td>\n",
       "      <td>93.207130</td>\n",
       "      <td>-19.473122</td>\n",
       "      <td>15.425479</td>\n",
       "      <td>-7.123735</td>\n",
       "      <td>3.265974</td>\n",
       "      <td>-15.967982</td>\n",
       "      <td>-3.900991</td>\n",
       "      <td>-7.250444</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>4</td>\n",
       "      <td>4.375</td>\n",
       "      <td>0.414578</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-340.562622</td>\n",
       "      <td>125.753433</td>\n",
       "      <td>60.192120</td>\n",
       "      <td>12.968719</td>\n",
       "      <td>8.342021</td>\n",
       "      <td>5.732525</td>\n",
       "      <td>-2.957875</td>\n",
       "      <td>2.134922</td>\n",
       "      <td>-7.303535</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-296.270172</td>\n",
       "      <td>96.759354</td>\n",
       "      <td>-10.450113</td>\n",
       "      <td>19.952477</td>\n",
       "      <td>-0.722513</td>\n",
       "      <td>-1.394691</td>\n",
       "      <td>-11.906327</td>\n",
       "      <td>-3.497026</td>\n",
       "      <td>-13.923201</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.875</td>\n",
       "      <td>0.892679</td>\n",
       "      <td>4</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.829156</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-270.380280</td>\n",
       "      <td>95.477310</td>\n",
       "      <td>-25.079927</td>\n",
       "      <td>45.097095</td>\n",
       "      <td>14.711880</td>\n",
       "      <td>14.881142</td>\n",
       "      <td>6.295753</td>\n",
       "      <td>16.971743</td>\n",
       "      <td>4.258063</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.125</td>\n",
       "      <td>0.739510</td>\n",
       "      <td>4</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-107.451653</td>\n",
       "      <td>17.363043</td>\n",
       "      <td>-24.690931</td>\n",
       "      <td>52.119267</td>\n",
       "      <td>5.604693</td>\n",
       "      <td>9.739891</td>\n",
       "      <td>2.110556</td>\n",
       "      <td>5.655409</td>\n",
       "      <td>6.965531</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.819680</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  harmonic_mfcc_mean_0  harmonic_mfcc_mean_1  harmonic_mfcc_mean_2  \\\n",
       "0        0           -234.011032             93.207130            -19.473122   \n",
       "1        1           -340.562622            125.753433             60.192120   \n",
       "2        2           -296.270172             96.759354            -10.450113   \n",
       "3        3           -270.380280             95.477310            -25.079927   \n",
       "4        4           -107.451653             17.363043            -24.690931   \n",
       "\n",
       "   harmonic_mfcc_mean_3  harmonic_mfcc_mean_4  harmonic_mfcc_mean_5  \\\n",
       "0             15.425479             -7.123735              3.265974   \n",
       "1             12.968719              8.342021              5.732525   \n",
       "2             19.952477             -0.722513             -1.394691   \n",
       "3             45.097095             14.711880             14.881142   \n",
       "4             52.119267              5.604693              9.739891   \n",
       "\n",
       "   harmonic_mfcc_mean_6  harmonic_mfcc_mean_7  harmonic_mfcc_mean_8  ...  \\\n",
       "0            -15.967982             -3.900991             -7.250444  ...   \n",
       "1             -2.957875              2.134922             -7.303535  ...   \n",
       "2            -11.906327             -3.497026            -13.923201  ...   \n",
       "3              6.295753             16.971743              4.258063  ...   \n",
       "4              2.110556              5.655409              6.965531  ...   \n",
       "\n",
       "   memorability_n_annotators  clarity  clarity_std  clarity_n_annotators  \\\n",
       "0                          4    4.000     0.353553                     4   \n",
       "1                          4    2.000     0.707107                     4   \n",
       "2                          4    2.875     0.892679                     4   \n",
       "3                          4    2.125     0.739510                     4   \n",
       "4                          4    1.625     0.819680                     4   \n",
       "\n",
       "   naturalness  naturalness_std  naturalness_n_annotators  gender  \\\n",
       "0        4.375         0.414578                         4    male   \n",
       "1        2.000         0.707107                         4    male   \n",
       "2        3.250         0.829156                         4    male   \n",
       "3        2.250         0.433013                         4    male   \n",
       "4        1.750         0.559017                         4  female   \n",
       "\n",
       "   num_annotators  harmonic_tempo  \n",
       "0               4             NaN  \n",
       "1               4             NaN  \n",
       "2               4             NaN  \n",
       "3               4             NaN  \n",
       "4               4             NaN  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if SAMPLE_SIZE is not None:\n",
    "    SAMPLE_SIZE = int(SAMPLE_SIZE)\n",
    "    if SAMPLE_SIZE <= 0:\n",
    "        raise ValueError('SAMPLE_SIZE must be None or a positive integer')\n",
    "    if SAMPLE_SIZE > df.shape[0]:\n",
    "        print('Requested SAMPLE_SIZE > nrows; using full dataframe instead.')\n",
    "    else:\n",
    "        df = df.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "        print('Sampled shape:', df.shape)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a0f7a",
   "metadata": {},
   "source": [
    "## Define columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31828188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts -> harmonic, percussive, original: 88 87 87\n",
      "Metadata cols detected: ['song_id', 'coherence_std', 'coherence_n_annotators', 'musicality_std', 'musicality_n_annotators', 'memorability_std', 'memorability_n_annotators', 'clarity_std', 'clarity_n_annotators', 'naturalness_std', 'naturalness_n_annotators', 'gender', 'num_annotators']\n"
     ]
    }
   ],
   "source": [
    "targets = ['coherence','musicality','memorability','clarity','naturalness']\n",
    "for t in targets:\n",
    "    if t not in df.columns:\n",
    "        raise ValueError(f\"Target column {t} not found in dataset\")\n",
    "\n",
    "harmonic_cols   = [c for c in df.columns if c.startswith('harmonic_')]\n",
    "percussive_cols = [c for c in df.columns if c.startswith('percussive_')]\n",
    "original_cols   = [c for c in df.columns if c.startswith('original_')]\n",
    "\n",
    "meta_cols = [c for c in df.columns if c not in harmonic_cols + percussive_cols + original_cols + targets]\n",
    "print('Counts -> harmonic, percussive, original:', len(harmonic_cols), len(percussive_cols), len(original_cols))\n",
    "print('Metadata cols detected:', meta_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230db4f",
   "metadata": {},
   "source": [
    "## Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48887ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded metadata columns: ['gender']\n",
      "Train/Test shapes: (425, 274) (75, 274)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [c for c in meta_cols if 'id' in c.lower()]\n",
    "X = df.drop(columns=drop_cols + targets).copy()\n",
    "y = df[targets].copy()\n",
    "\n",
    "# One-hot small-cardinality categorical metadata if present\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == 'object' and X[c].nunique() < 30]\n",
    "if cat_cols:\n",
    "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    print('One-hot encoded metadata columns:', cat_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=RANDOM_STATE)\n",
    "print('Train/Test shapes:', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda62ee",
   "metadata": {},
   "source": [
    "## Evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preds(y_true, y_pred, names=targets):\n",
    "    rows = []\n",
    "    for i, t in enumerate(names):\n",
    "        rmse = root_mean_squared_error(y_true.iloc[:,i], y_pred[:,i])\n",
    "        mae = mean_absolute_error(y_true.iloc[:,i], y_pred[:,i])\n",
    "        r2 = r2_score(y_true.iloc[:,i], y_pred[:,i])\n",
    "        rows.append({'target': t, 'rmse': float(rmse), 'mae': float(mae), 'r2': float(r2)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076aec4",
   "metadata": {},
   "source": [
    "## Global preprocessing pipeline\n",
    "\n",
    "variance threshold -> median impute -> robust scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20268a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: preproc_global_20251125_085822_31e5c799.joblib, metadata: preproc_global_20251125_085822_31e5c799.json\n"
     ]
    }
   ],
   "source": [
    "numeric_features = [c for c in harmonic_cols + percussive_cols + original_cols if c in X.columns]\n",
    "\n",
    "global_preproc = Pipeline([\n",
    "    ('var', VarianceThreshold(1e-5)),\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', RobustScaler())\n",
    "])\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    global_preproc.fit(X_train[numeric_features])\n",
    "    if SAVE_PREPROCESSORS:\n",
    "        save_artifact(global_preproc, 'preproc_global', metadata={'type':'global_preproc','features_count':len(numeric_features)})\n",
    "else:\n",
    "    print('No numeric features detected matching harmonic/percussive/original prefixes.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5050b",
   "metadata": {},
   "source": [
    "## Early Fusion: Train RF on all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb59054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early fusion evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coherence</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.704720</td>\n",
       "      <td>0.376646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musicality</td>\n",
       "      <td>0.800818</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>0.500424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorability</td>\n",
       "      <td>0.788027</td>\n",
       "      <td>0.673390</td>\n",
       "      <td>0.408859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clarity</td>\n",
       "      <td>0.837665</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.416418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naturalness</td>\n",
       "      <td>0.786678</td>\n",
       "      <td>0.668941</td>\n",
       "      <td>0.471780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target      rmse       mae        r2\n",
       "0     coherence  0.850769  0.704720  0.376646\n",
       "1    musicality  0.800818  0.641452  0.500424\n",
       "2  memorability  0.788027  0.673390  0.408859\n",
       "3       clarity  0.837665  0.678682  0.416418\n",
       "4   naturalness  0.786678  0.668941  0.471780"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: early_rf_20251125_085841_6a9f1200.joblib, metadata: early_rf_20251125_085841_6a9f1200.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    early_pipe = Pipeline([\n",
    "        ('pre', global_preproc),\n",
    "        ('model', MultiOutputRegressor(RandomForestRegressor(n_estimators=EARLY_RF_N_ESTIMATORS, n_jobs=-1, random_state=RANDOM_STATE)))\n",
    "    ])\n",
    "    early_pipe.fit(X_train[numeric_features], y_train)\n",
    "    \n",
    "    y_pred_early = early_pipe.predict(X_test[numeric_features])\n",
    "    df_eval_early = eval_preds(y_test, y_pred_early)\n",
    "    \n",
    "    print('Early fusion evaluation:')\n",
    "    display(df_eval_early)\n",
    "    \n",
    "    if SAVE_PREPROCESSORS:\n",
    "        save_artifact(early_pipe, 'early_rf', metadata={'fusion':'early','model':'RandomForest','n_features':len(numeric_features)})\n",
    "    else:\n",
    "        joblib.dump(early_pipe, MODELS_DIR + '/early_rf.joblib')\n",
    "else:\n",
    "    print('Skipping early fusion: no numeric features available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18fca1",
   "metadata": {},
   "source": [
    "## Late Fusion: per-stem models + meta-learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: pre_harmonic_20251125_085846_a4823244.joblib, metadata: pre_harmonic_20251125_085846_a4823244.json\n",
      "Saved: base_harmonic_rf_20251125_085846_b1c5bb48.joblib, metadata: base_harmonic_rf_20251125_085846_b1c5bb48.json\n",
      "Saved: pre_percussive_20251125_085853_55f0afb5.joblib, metadata: pre_percussive_20251125_085853_55f0afb5.json\n",
      "Saved: base_percussive_rf_20251125_085853_b491d409.joblib, metadata: base_percussive_rf_20251125_085853_b491d409.json\n",
      "Saved: pre_original_20251125_085859_55f0afb5.joblib, metadata: pre_original_20251125_085859_55f0afb5.json\n",
      "Saved: base_original_rf_20251125_085859_b491d409.joblib, metadata: base_original_rf_20251125_085859_b491d409.json\n",
      "Late fusion evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coherence</td>\n",
       "      <td>0.823509</td>\n",
       "      <td>0.669306</td>\n",
       "      <td>0.415952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musicality</td>\n",
       "      <td>0.763946</td>\n",
       "      <td>0.602148</td>\n",
       "      <td>0.545368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorability</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.648934</td>\n",
       "      <td>0.443667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clarity</td>\n",
       "      <td>0.836851</td>\n",
       "      <td>0.659154</td>\n",
       "      <td>0.417551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naturalness</td>\n",
       "      <td>0.762419</td>\n",
       "      <td>0.642870</td>\n",
       "      <td>0.503855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target      rmse       mae        r2\n",
       "0     coherence  0.823509  0.669306  0.415952\n",
       "1    musicality  0.763946  0.602148  0.545368\n",
       "2  memorability  0.764474  0.648934  0.443667\n",
       "3       clarity  0.836851  0.659154  0.417551\n",
       "4   naturalness  0.762419  0.642870  0.503855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: late_meta_ridge_20251125_085906_cb501d1b.joblib, metadata: late_meta_ridge_20251125_085906_cb501d1b.json\n"
     ]
    }
   ],
   "source": [
    "def make_group_preproc(cols):\n",
    "    p = Pipeline([('var', VarianceThreshold(1e-5)),\n",
    "                  ('impute', SimpleImputer(strategy='median')),\n",
    "                  ('scale', RobustScaler())])\n",
    "    p.fit(X_train[cols])\n",
    "    return p\n",
    "\n",
    "h_cols = [c for c in harmonic_cols if c in X.columns]\n",
    "p_cols = [c for c in percussive_cols if c in X.columns]\n",
    "o_cols = [c for c in original_cols if c in X.columns]\n",
    "\n",
    "pre_h = make_group_preproc(h_cols) if h_cols else None\n",
    "pre_p = make_group_preproc(p_cols) if p_cols else None\n",
    "pre_o = make_group_preproc(o_cols) if o_cols else None\n",
    "\n",
    "base_h = MultiOutputRegressor(RandomForestRegressor(n_estimators=BASE_RF_N_ESTIMATORS, n_jobs=-1, random_state=RANDOM_STATE)) if h_cols else None\n",
    "base_p = MultiOutputRegressor(RandomForestRegressor(n_estimators=BASE_RF_N_ESTIMATORS, n_jobs=-1, random_state=RANDOM_STATE)) if p_cols else None\n",
    "base_o = MultiOutputRegressor(RandomForestRegressor(n_estimators=BASE_RF_N_ESTIMATORS, n_jobs=-1, random_state=RANDOM_STATE)) if o_cols else None\n",
    "\n",
    "if h_cols:\n",
    "    base_h.fit(pre_h.transform(X_train[h_cols]), y_train)\n",
    "    if SAVE_PREPROCESSORS:\n",
    "        save_artifact(pre_h, 'pre_harmonic', metadata={'cols':len(h_cols)})\n",
    "        save_artifact(base_h, 'base_harmonic_rf', metadata={'cols':len(h_cols),'model':'RandomForest'})\n",
    "if p_cols:\n",
    "    base_p.fit(pre_p.transform(X_train[p_cols]), y_train)\n",
    "    if SAVE_PREPROCESSORS:\n",
    "        save_artifact(pre_p, 'pre_percussive', metadata={'cols':len(p_cols)})\n",
    "        save_artifact(base_p, 'base_percussive_rf', metadata={'cols':len(p_cols),'model':'RandomForest'})\n",
    "if o_cols:\n",
    "    base_o.fit(pre_o.transform(X_train[o_cols]), y_train)\n",
    "    if SAVE_PREPROCESSORS:\n",
    "        save_artifact(pre_o, 'pre_original', metadata={'cols':len(o_cols)})\n",
    "        save_artifact(base_o, 'base_original_rf', metadata={'cols':len(o_cols),'model':'RandomForest'})\n",
    "\n",
    "# Build meta features (note: for strict stacking use out-of-fold preds; this uses full-train preds for speed)\n",
    "meta_tr = []\n",
    "meta_te = []\n",
    "if h_cols:\n",
    "    meta_tr.append(base_h.predict(pre_h.transform(X_train[h_cols])))\n",
    "    meta_te.append(base_h.predict(pre_h.transform(X_test[h_cols])))\n",
    "if p_cols:\n",
    "    meta_tr.append(base_p.predict(pre_p.transform(X_train[p_cols])))\n",
    "    meta_te.append(base_p.predict(pre_p.transform(X_test[p_cols])))\n",
    "if o_cols:\n",
    "    meta_tr.append(base_o.predict(pre_o.transform(X_train[o_cols])))\n",
    "    meta_te.append(base_o.predict(pre_o.transform(X_test[o_cols])))\n",
    "\n",
    "if meta_tr:\n",
    "    meta_tr = np.hstack(meta_tr)\n",
    "    meta_te = np.hstack(meta_te)\n",
    "    meta_learner = MultiOutputRegressor(Ridge())\n",
    "    meta_learner.fit(meta_tr, y_train)\n",
    "    y_pred_late = meta_learner.predict(meta_te)\n",
    "    df_eval_late = eval_preds(y_test, y_pred_late)\n",
    "    print('Late fusion evaluation:')\n",
    "    display(df_eval_late)\n",
    "    save_artifact(meta_learner, 'late_meta_ridge', metadata={'fusion':'late','base':'rf','meta':'ridge'})\n",
    "else:\n",
    "    print('Skipping late fusion: no base models trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f1975",
   "metadata": {},
   "source": [
    "## Hybrid fusion\n",
    "\n",
    "PCA per-group -> concat -> GBR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: pca_harmonic_20251125_085906_a4823244.joblib, metadata: pca_harmonic_20251125_085906_a4823244.json\n",
      "Saved: pca_percussive_20251125_085906_55f0afb5.joblib, metadata: pca_percussive_20251125_085906_55f0afb5.json\n",
      "Saved: pca_original_20251125_085906_55f0afb5.joblib, metadata: pca_original_20251125_085906_55f0afb5.json\n",
      "Hybrid fusion evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coherence</td>\n",
       "      <td>0.792816</td>\n",
       "      <td>0.640812</td>\n",
       "      <td>0.458677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musicality</td>\n",
       "      <td>0.772365</td>\n",
       "      <td>0.624150</td>\n",
       "      <td>0.535293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorability</td>\n",
       "      <td>0.767793</td>\n",
       "      <td>0.604732</td>\n",
       "      <td>0.438827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clarity</td>\n",
       "      <td>0.841932</td>\n",
       "      <td>0.664599</td>\n",
       "      <td>0.410458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naturalness</td>\n",
       "      <td>0.807427</td>\n",
       "      <td>0.654685</td>\n",
       "      <td>0.443549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target      rmse       mae        r2\n",
       "0     coherence  0.792816  0.640812  0.458677\n",
       "1    musicality  0.772365  0.624150  0.535293\n",
       "2  memorability  0.767793  0.604732  0.438827\n",
       "3       clarity  0.841932  0.664599  0.410458\n",
       "4   naturalness  0.807427  0.654685  0.443549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: hybrid_gbr_20251125_090010_a73d1efc.joblib, metadata: hybrid_gbr_20251125_090010_a73d1efc.json\n"
     ]
    }
   ],
   "source": [
    "pca_h = pca_p = pca_o = None\n",
    "H_tr = P_tr = O_tr = None\n",
    "H_te = P_te = O_te = None\n",
    "\n",
    "if h_cols:\n",
    "    pca_h = PCA(n_components=0.95, svd_solver='full', random_state=RANDOM_STATE)\n",
    "    H_tr = pca_h.fit_transform(pre_h.transform(X_train[h_cols]))\n",
    "    H_te = pca_h.transform(pre_h.transform(X_test[h_cols]))\n",
    "    if SAVE_PREPROCESSORS: save_artifact(pca_h, 'pca_harmonic', metadata={'cols':len(h_cols)})\n",
    "if p_cols:\n",
    "    pca_p = PCA(n_components=0.95, svd_solver='full', random_state=RANDOM_STATE)\n",
    "    P_tr = pca_p.fit_transform(pre_p.transform(X_train[p_cols]))\n",
    "    P_te = pca_p.transform(pre_p.transform(X_test[p_cols]))\n",
    "    if SAVE_PREPROCESSORS: save_artifact(pca_p, 'pca_percussive', metadata={'cols':len(p_cols)})\n",
    "if o_cols:\n",
    "    pca_o = PCA(n_components=0.95, svd_solver='full', random_state=RANDOM_STATE)\n",
    "    O_tr = pca_o.fit_transform(pre_o.transform(X_train[o_cols]))\n",
    "    O_te = pca_o.transform(pre_o.transform(X_test[o_cols]))\n",
    "    if SAVE_PREPROCESSORS: save_artifact(pca_o, 'pca_original', metadata={'cols':len(o_cols)})\n",
    "\n",
    "parts_tr = [p for p in [H_tr, P_tr, O_tr] if p is not None]\n",
    "parts_te = [p for p in [H_te, P_te, O_te] if p is not None]\n",
    "\n",
    "if parts_tr:\n",
    "    X_hybrid_tr = np.hstack(parts_tr)\n",
    "    X_hybrid_te = np.hstack(parts_te)\n",
    "    hybrid_model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=HYBRID_GBR_N_ESTIMATORS, random_state=RANDOM_STATE))\n",
    "    hybrid_model.fit(X_hybrid_tr, y_train)\n",
    "    y_pred_hybrid = hybrid_model.predict(X_hybrid_te)\n",
    "    df_eval_hybrid = eval_preds(y_test, y_pred_hybrid)\n",
    "    print('Hybrid fusion evaluation:')\n",
    "    display(df_eval_hybrid)\n",
    "    save_artifact(hybrid_model, 'hybrid_gbr', metadata={'fusion':'hybrid','reduced_dim':X_hybrid_tr.shape[1]})\n",
    "else:\n",
    "    print('Skipping hybrid fusion: no group representations available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4810a36",
   "metadata": {},
   "source": [
    "## train and save separate model per target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203d0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training per-target RF for: coherence\n",
      "Saved: separate_rf_coherence_20251125_090013_1ae6786d.joblib, metadata: separate_rf_coherence_20251125_090013_1ae6786d.json\n",
      "  coherence RMSE: 0.8508\n",
      "Training per-target RF for: musicality\n",
      "Saved: separate_rf_musicality_20251125_090018_534ce428.joblib, metadata: separate_rf_musicality_20251125_090018_534ce428.json\n",
      "  musicality RMSE: 0.8008\n",
      "Training per-target RF for: memorability\n",
      "Saved: separate_rf_memorability_20251125_090022_6cc2f731.joblib, metadata: separate_rf_memorability_20251125_090022_6cc2f731.json\n",
      "  memorability RMSE: 0.7880\n",
      "Training per-target RF for: clarity\n",
      "Saved: separate_rf_clarity_20251125_090027_bcccad7f.joblib, metadata: separate_rf_clarity_20251125_090027_bcccad7f.json\n",
      "  clarity RMSE: 0.8377\n",
      "Training per-target RF for: naturalness\n",
      "Saved: separate_rf_naturalness_20251125_090031_aa93c9f3.joblib, metadata: separate_rf_naturalness_20251125_090031_aa93c9f3.json\n",
      "  naturalness RMSE: 0.7867\n"
     ]
    }
   ],
   "source": [
    "for t in targets:\n",
    "    print('Training per-target RF for:', t)\n",
    "    model = Pipeline([\n",
    "        ('pre', global_preproc),\n",
    "        ('rf', RandomForestRegressor(n_estimators=EARLY_RF_N_ESTIMATORS, n_jobs=-1, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    model.fit(X_train[numeric_features], y_train[t])\n",
    "    save_artifact(model, f'separate_rf_{t}', metadata={'target': t, 'model': 'RandomForest'})\n",
    "    pred = model.predict(X_test[numeric_features])\n",
    "    rmse = root_mean_squared_error(y_test[t], pred)\n",
    "    print(f'  {t} RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4dcd79",
   "metadata": {},
   "source": [
    "## Save manifest and evaluation summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bef999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>early</th>\n",
       "      <th>late</th>\n",
       "      <th>hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coherence</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.823509</td>\n",
       "      <td>0.792816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musicality</td>\n",
       "      <td>0.800818</td>\n",
       "      <td>0.763946</td>\n",
       "      <td>0.772365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorability</td>\n",
       "      <td>0.788027</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.767793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clarity</td>\n",
       "      <td>0.837665</td>\n",
       "      <td>0.836851</td>\n",
       "      <td>0.841932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naturalness</td>\n",
       "      <td>0.786678</td>\n",
       "      <td>0.762419</td>\n",
       "      <td>0.807427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target     early      late    hybrid\n",
       "0     coherence  0.850769  0.823509  0.792816\n",
       "1    musicality  0.800818  0.763946  0.772365\n",
       "2  memorability  0.788027  0.764474  0.767793\n",
       "3       clarity  0.837665  0.836851  0.841932\n",
       "4   naturalness  0.786678  0.762419  0.807427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifacts = []\n",
    "for f in Path(MODELS_DIR).iterdir():\n",
    "    artifacts.append({'name': f.name, 'path': str(f)})\n",
    "manifest_path = Path(MODELS_DIR) / 'manifest.json'\n",
    "with open(manifest_path, 'w') as f:\n",
    "    json.dump(artifacts, f, indent=2)\n",
    "\n",
    "# collect eval summaries if present in notebook variables (best-effort)\n",
    "eval_frames = {}\n",
    "if 'df_eval_early' in globals():\n",
    "    eval_frames['early'] = df_eval_early.set_index('target')['rmse']\n",
    "if 'df_eval_late' in globals():\n",
    "    eval_frames['late'] = df_eval_late.set_index('target')['rmse']\n",
    "if 'df_eval_hybrid' in globals():\n",
    "    eval_frames['hybrid'] = df_eval_hybrid.set_index('target')['rmse']\n",
    "\n",
    "if eval_frames:\n",
    "    eval_summary = pd.concat(eval_frames, axis=1)\n",
    "    eval_summary.reset_index(inplace=True)\n",
    "    eval_summary.rename(columns={'index':'target'}, inplace=True)\n",
    "    eval_summary.to_csv(Path(MODELS_DIR)/'eval_summary_rmse.csv', index=False)\n",
    "    display(eval_summary)\n",
    "else:\n",
    "    print('No eval summaries to write.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
